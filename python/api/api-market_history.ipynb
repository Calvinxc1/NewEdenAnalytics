{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from datetime import timedelta, datetime, date\n",
    "import io\n",
    "import tarfile as tf\n",
    "import gzip as gz\n",
    "import pandas as pd\n",
    "\n",
    "from ApiHandler import ApiHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiMarketHistory(ApiHandler):\n",
    "    settings = {\n",
    "        **ApiHandler.settings,\n",
    "        'day_delay': 2,\n",
    "        'record_warning': 40000\n",
    "    }\n",
    "    url = {\n",
    "        **ApiHandler.url,\n",
    "        'data': 'https://storage.googleapis.com/evekit_md/{year:04}/{month:02}/{day:02}/market_{year:04}{month:02}{day:02}.tgz',\n",
    "    }\n",
    "    sql = {\n",
    "        **ApiHandler.sql,\n",
    "        'date_check': 'SELECT DISTINCT record_date FROM MarketHistory;'\n",
    "    }\n",
    "    script_vals = {\n",
    "        **ApiHandler.script_vals,\n",
    "        'table': 'MarketHistory'\n",
    "    }\n",
    "    name = 'EVEKit Market History API'\n",
    "    \n",
    "    @property\n",
    "    def data_date(self):\n",
    "        data_date = date.today() - timedelta(days=self.settings['day_delay'])\n",
    "        return data_date\n",
    "            \n",
    "    def get_raw_data(self, date=None):\n",
    "        if date is None: date = self.data_date\n",
    "        if self.verbose: self._verbose('get_raw_data', 'Getting raw data for date {date}...'.format(**{'date': date}))\n",
    "        \n",
    "        data_conn = rq.get(self.url['data'].format(**{\n",
    "            'year': date.year,\n",
    "            'month': date.month,\n",
    "            'day': date.day\n",
    "        }))\n",
    "        \n",
    "        if data_conn.status_code != 200:\n",
    "            raise Exception(\"\"\"\\\n",
    "                Connection returned a {status} code on pull for {date}.\n",
    "                Message body:\n",
    "                {body}\\\n",
    "            \"\"\".format(**{\n",
    "                'status':data_conn.status_code,\n",
    "                'date': date,\n",
    "                'body':data_conn.content.decode('utf-8')\n",
    "            }))\n",
    "            \n",
    "        if self.verbose: self._verbose('get_raw_data', 'Raw data acquired.')\n",
    "        return data_conn.content\n",
    "            \n",
    "    def build_data(self, raw_data):\n",
    "        if self.verbose: self._verbose('build_data', 'Building data frame...')\n",
    "        tar_file = tf.open(fileobj=io.BytesIO(raw_data))\n",
    "    \n",
    "        data_frame = pd.concat([\n",
    "            self._parse_data(tar_file.extractfile(type_file).read())\n",
    "            for type_file in tar_file\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "        data_frame['record_date'] = pd.to_datetime(data_frame['record_date']/1000,unit='s').dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        if self.verbose: self._verbose('build_data', 'Data frame built. %s records.' % len(data_frame))\n",
    "            \n",
    "        if len(data_frame) < self.settings['record_warning']:\n",
    "            if self.verbose:\n",
    "                self._verbose(\n",
    "                    'build_data', \n",
    "                    'Data frame is {records}, which is under warning threshold of {record_warning} records. Sending e-mail.'.format(**{\n",
    "                        'records': len(data_frame),\n",
    "                        'record_warning': self.settings['record_warning']\n",
    "                    })\n",
    "                )\n",
    "            self._email(\n",
    "                'warning',\n",
    "                \"\"\"\\\n",
    "                Data extracted for date {date} has {records}, which is below the threshold of {record_warning} records.\n",
    "                This is a warning, not an error. Barring no other problems, the process will complete sucessfully.\\\n",
    "                \"\"\".format(**{\n",
    "                    'date': data_frame['record_date'].unique()[0],\n",
    "                    'records': len(data_frame),\n",
    "                    'record_warning': self.settings['record_warning']\n",
    "                })\n",
    "            )\n",
    "            \n",
    "        error_rows = data_frame['avg_price'] > data_frame['high_price']\n",
    "        if error_rows.sum() > 0:\n",
    "            if self.verbose:\n",
    "                self._verbose(\n",
    "                    'build_data', \n",
    "                    'Data frame has {records} with flipped avg_price and high_price. Correcting & sending e-mail.'.format(**{\n",
    "                        'records': error_rows.sum(),\n",
    "                        'record_warning': self.settings['record_warning']\n",
    "                    })\n",
    "                )\n",
    "            self._email(\n",
    "                'warning',\n",
    "                \"\"\"\\\n",
    "                Data extracted for date {date} has {records} with flipped avg_price and high_price. Values are corrected.\n",
    "                This is a warning, not an error. Barring no other problems, the process will complete sucessfully.\\\n",
    "                \"\"\".format(**{\n",
    "                    'date': data_frame['record_date'].unique()[0],\n",
    "                    'records': error_rows.sum(),\n",
    "                    'record_warning': self.settings['record_warning']\n",
    "                })\n",
    "            )\n",
    "            data_frame.loc[error_rows] = data_frame.loc[error_rows].rename(columns={'avg_price':'high_price', 'high_price':'avg_price'})\n",
    "            \n",
    "        return data_frame\n",
    "        \n",
    "    def _parse_data(self, type_file):\n",
    "        data_file = pd.read_csv(\n",
    "            io.BytesIO(gz.open(io.BytesIO(type_file)).read()),\n",
    "            header=None, index_col=None,\n",
    "            names=('type_id','region_id','order_count','low_price','avg_price','high_price','volume','record_date')\n",
    "        )\n",
    "        return data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = ApiMarketHistory()\n",
    "#api.run_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tqdm\n",
    "#for date_val in tqdm.tqdm_notebook(pd.date_range(date(2019,7,27), date(2019,8,23))):\n",
    "raw_data = api.get_raw_data(date(2019,9,25))\n",
    "#data_frame = api.build_data(raw_data)\n",
    "#api.insert_data(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_file = tf.open(fileobj=io.BytesIO(raw_data))\n",
    "\n",
    "data_files = pd.concat([\n",
    "    api._parse_data(tar_file.extractfile(type_file).read())\n",
    "    for type_file in tar_file\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_id</th>\n",
       "      <th>region_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>low_price</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>record_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>10000016</td>\n",
       "      <td>27</td>\n",
       "      <td>3.980000e+01</td>\n",
       "      <td>4.828000e+01</td>\n",
       "      <td>4.800000e+01</td>\n",
       "      <td>533047</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>10000064</td>\n",
       "      <td>43</td>\n",
       "      <td>3.671000e+01</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>3.720000e+01</td>\n",
       "      <td>1206728</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>10000002</td>\n",
       "      <td>63</td>\n",
       "      <td>3.501000e+01</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>4.996000e+01</td>\n",
       "      <td>3305782</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>10000016</td>\n",
       "      <td>24</td>\n",
       "      <td>7.501000e+01</td>\n",
       "      <td>3.739900e+02</td>\n",
       "      <td>1.900000e+02</td>\n",
       "      <td>170029</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>10000067</td>\n",
       "      <td>8</td>\n",
       "      <td>1.210000e+02</td>\n",
       "      <td>3.889900e+02</td>\n",
       "      <td>2.790000e+02</td>\n",
       "      <td>64664</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43286</td>\n",
       "      <td>52694</td>\n",
       "      <td>10000032</td>\n",
       "      <td>10</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>4.499000e+06</td>\n",
       "      <td>4.230714e+06</td>\n",
       "      <td>22</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43289</td>\n",
       "      <td>52694</td>\n",
       "      <td>10000035</td>\n",
       "      <td>4</td>\n",
       "      <td>1.696000e+06</td>\n",
       "      <td>1.698759e+06</td>\n",
       "      <td>1.696345e+06</td>\n",
       "      <td>8</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43292</td>\n",
       "      <td>52694</td>\n",
       "      <td>10000039</td>\n",
       "      <td>15</td>\n",
       "      <td>1.900000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>1.920690e+06</td>\n",
       "      <td>29</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43294</td>\n",
       "      <td>52694</td>\n",
       "      <td>10000069</td>\n",
       "      <td>5</td>\n",
       "      <td>2.489000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.490571e+06</td>\n",
       "      <td>7</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43301</td>\n",
       "      <td>52704</td>\n",
       "      <td>10000002</td>\n",
       "      <td>4</td>\n",
       "      <td>1.069670e+08</td>\n",
       "      <td>2.246653e+08</td>\n",
       "      <td>1.658162e+08</td>\n",
       "      <td>4</td>\n",
       "      <td>1569369600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14783 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type_id  region_id  order_count     low_price     avg_price  \\\n",
       "1           18   10000016           27  3.980000e+01  4.828000e+01   \n",
       "2           18   10000064           43  3.671000e+01  4.500000e+01   \n",
       "4           18   10000002           63  3.501000e+01  5.000000e+01   \n",
       "22          20   10000016           24  7.501000e+01  3.739900e+02   \n",
       "32          20   10000067            8  1.210000e+02  3.889900e+02   \n",
       "...        ...        ...          ...           ...           ...   \n",
       "43286    52694   10000032           10  2.500000e+06  4.499000e+06   \n",
       "43289    52694   10000035            4  1.696000e+06  1.698759e+06   \n",
       "43292    52694   10000039           15  1.900000e+06  2.500000e+06   \n",
       "43294    52694   10000069            5  2.489000e+06  2.500000e+06   \n",
       "43301    52704   10000002            4  1.069670e+08  2.246653e+08   \n",
       "\n",
       "         high_price   volume    record_date  \n",
       "1      4.800000e+01   533047  1569369600000  \n",
       "2      3.720000e+01  1206728  1569369600000  \n",
       "4      4.996000e+01  3305782  1569369600000  \n",
       "22     1.900000e+02   170029  1569369600000  \n",
       "32     2.790000e+02    64664  1569369600000  \n",
       "...             ...      ...            ...  \n",
       "43286  4.230714e+06       22  1569369600000  \n",
       "43289  1.696345e+06        8  1569369600000  \n",
       "43292  1.920690e+06       29  1569369600000  \n",
       "43294  2.490571e+06        7  1569369600000  \n",
       "43301  1.658162e+08        4  1569369600000  \n",
       "\n",
       "[14783 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data_files['avg_price'] > data_files['high_price']\n",
    "data_files.loc[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
